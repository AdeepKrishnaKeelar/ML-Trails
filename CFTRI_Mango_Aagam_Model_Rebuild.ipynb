{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CFTRI_Mango_Aagam_Model_Rebuild",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sfT5mA1oVzk64_r-HXIMDqzFzRVZk9Ce",
      "authorship_tag": "ABX9TyMFUu3kj+YVXIf7P43PmTxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdeepKrishnaKeelar/ML-Trails/blob/master/CFTRI_Mango_Aagam_Model_Rebuild.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "yPaOIchf1lGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import tensorflow\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "SCbge5_f42fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = ImageDataGenerator(\n",
        "    rescale=1/255,\n",
        "    zca_whitening=False, #applying zca_whitening\n",
        "    rotation_range=45, #rotating images 45 degrees\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")"
      ],
      "metadata": {
        "id": "wbGbgfD-ZEY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = train.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Data/CFTRI Dataset/CFTRI/train/\",\n",
        "    target_size=(200,200),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtKQnsSTZKvj",
        "outputId": "ebf91326-0190-4ced-eaba-96f3cb7af8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 206 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbwAwfVFZfbJ",
        "outputId": "9f73dea4-a900-4dfc-dda2-9a5b2e6b5e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'calcium_cold': 0,\n",
              " 'cold_etheral': 1,\n",
              " 'hot_calcium': 2,\n",
              " 'hot_etheral': 3,\n",
              " 'hot_natural': 4,\n",
              " 'natural': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tensorflow.keras.models.Sequential([\n",
        "    tensorflow.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tensorflow.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tensorflow.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tensorflow.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tensorflow.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tensorflow.keras.layers.Dense(512, activation='relu'),\n",
        "    # Output neuron\n",
        "    tensorflow.keras.layers.Dense(6, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "1wiCZfwDZkDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              #optimizer=RMSprop(learning_rate=0.001),\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QWzk4WypaKgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tensorflow.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.90):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "model_fit = model.fit(training_dataset,\n",
        "                      steps_per_epoch = 10,\n",
        "                      epochs=32)\n",
        "                    #  callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7zVdNd8aYzI",
        "outputId": "1884c4b9-ea67-4405-a2c3-3ac794779d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "10/10 [==============================] - 41s 4s/step - loss: 1.2204 - accuracy: 0.2278\n",
            "Epoch 2/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4823 - accuracy: 0.3038\n",
            "Epoch 3/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4364 - accuracy: 0.2658\n",
            "Epoch 4/32\n",
            "10/10 [==============================] - 42s 4s/step - loss: 0.4285 - accuracy: 0.2468\n",
            "Epoch 5/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4199 - accuracy: 0.3354\n",
            "Epoch 6/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4089 - accuracy: 0.3375\n",
            "Epoch 7/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4161 - accuracy: 0.3165\n",
            "Epoch 8/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4287 - accuracy: 0.3038\n",
            "Epoch 9/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4262 - accuracy: 0.2975\n",
            "Epoch 10/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4139 - accuracy: 0.3228\n",
            "Epoch 11/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4035 - accuracy: 0.3734\n",
            "Epoch 12/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4065 - accuracy: 0.3481\n",
            "Epoch 13/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4111 - accuracy: 0.3544\n",
            "Epoch 14/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4090 - accuracy: 0.3562\n",
            "Epoch 15/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4028 - accuracy: 0.4375\n",
            "Epoch 16/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4017 - accuracy: 0.4051\n",
            "Epoch 17/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.3931 - accuracy: 0.3875\n",
            "Epoch 18/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.3804 - accuracy: 0.4000\n",
            "Epoch 19/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4182 - accuracy: 0.3125\n",
            "Epoch 20/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.3868 - accuracy: 0.4250\n",
            "Epoch 21/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4068 - accuracy: 0.3987\n",
            "Epoch 22/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4056 - accuracy: 0.3625\n",
            "Epoch 23/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.3998 - accuracy: 0.4114\n",
            "Epoch 24/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4029 - accuracy: 0.4304\n",
            "Epoch 25/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.3938 - accuracy: 0.4177\n",
            "Epoch 26/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.3956 - accuracy: 0.4062\n",
            "Epoch 27/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.3817 - accuracy: 0.4620\n",
            "Epoch 28/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4011 - accuracy: 0.4304\n",
            "Epoch 29/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4017 - accuracy: 0.3671\n",
            "Epoch 30/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.3926 - accuracy: 0.4313\n",
            "Epoch 31/32\n",
            "10/10 [==============================] - 40s 4s/step - loss: 0.4017 - accuracy: 0.4000\n",
            "Epoch 32/32\n",
            "10/10 [==============================] - 39s 4s/step - loss: 0.4089 - accuracy: 0.3671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = training_dataset.class_indices\n",
        "inverted_classes = dict(map(reversed, classes.items()))\n",
        "print(inverted_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s2ALNsRcahY",
        "outputId": "8bfe18fa-5e7f-4b07-a879-8091c865af62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'calcium_cold', 1: 'cold_etheral', 2: 'hot_calcium', 3: 'hot_etheral', 4: 'hot_natural', 5: 'natural'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib be here soon"
      ],
      "metadata": {
        "id": "2E1bB8IDfxqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/drive/MyDrive/Data/CFTRI Dataset/CFTRI/test'\n",
        "total = 0\n",
        "correct = 0\n",
        "print(\"Predicted Value\",\"Actual Value\",sep=\"---\")\n",
        "for i in os.listdir(dir_path):\n",
        "  path = os.path.join(dir_path,i)\n",
        "  # print(path)\n",
        "\n",
        "  for j in os.listdir(path):\n",
        "    path1 = os.path.join(path,j)\n",
        "    \n",
        "    img = image.load_img(path+'//'+j,target_size=(200,200,3))\n",
        "\n",
        "\n",
        "    X = image.img_to_array(img)\n",
        "    X = np.expand_dims(X,axis=0)\n",
        "    images=np.vstack([X])\n",
        "    predictions = model.predict(images)\n",
        "    classes = np.argmax(predictions, axis = 1)\n",
        "    print(inverted_classes[classes[0]],i,sep=\"---\")\n",
        "    total+=1;\n",
        "    if(inverted_classes[classes[0]]==i):\n",
        "      correct+=1;\n",
        "\n",
        "\n",
        "print(\"Correct\",correct);\n",
        "print(\"Total\",total);\n",
        "   \n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPfUePjscf5O",
        "outputId": "b23d8a25-0445-4707-ceca-885ef06162c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value---Actual Value\n",
            "natural---hot_calcium\n",
            "natural---hot_calcium\n",
            "hot_natural---natural\n",
            "natural---natural\n",
            "natural---natural\n",
            "natural---natural\n",
            "hot_natural---natural\n",
            "hot_natural---natural\n",
            "hot_natural---natural\n",
            "hot_natural---hot_natural\n",
            "hot_natural---hot_natural\n",
            "natural---hot_natural\n",
            "hot_natural---hot_natural\n",
            "hot_natural---hot_natural\n",
            "hot_natural---hot_natural\n",
            "natural---hot_natural\n",
            "natural---hot_natural\n",
            "hot_natural---hot_etheral\n",
            "natural---hot_etheral\n",
            "natural---hot_etheral\n",
            "natural---hot_etheral\n",
            "hot_natural---hot_etheral\n",
            "natural---hot_etheral\n",
            "natural---hot_etheral\n",
            "natural---hot_etheral\n",
            "hot_natural---hot_etheral\n",
            "hot_natural---hot_etheral\n",
            "hot_natural---calcium_cold\n",
            "natural---calcium_cold\n",
            "hot_natural---calcium_cold\n",
            "hot_natural---calcium_cold\n",
            "hot_natural---calcium_cold\n",
            "hot_natural---cold_etheral\n",
            "natural---cold_etheral\n",
            "natural---cold_etheral\n",
            "natural---cold_etheral\n",
            "hot_natural---cold_etheral\n",
            "Correct 8\n",
            "Total 37\n"
          ]
        }
      ]
    }
  ]
}